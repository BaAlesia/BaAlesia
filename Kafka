Apache Kafka — это распределённая система потоковой обработки сообщений, которая используется для передачи данных в реальном времени. Она позволяет приложениям обмениваться данными в формате "произвёл-сохранил-доставил". Kafka оптимизирована для работы с большими объёмами данных, обеспечивая высокую производительность и устойчивость к сбоям.


---

Основные компоненты Kafka

1. Producers (Производители)
Это приложения или устройства, которые генерируют сообщения и отправляют их в Kafka. Например, веб-сайт может отправлять информацию о заказах, а IoT-устройства — данные о температуре.

2. Brokers (Брокеры)
Kafka — это кластер брокеров. Каждый брокер — это сервер, который хранит сообщения и отвечает за их доставку. Kafka автоматически распределяет нагрузку между брокерами, чтобы обеспечивать масштабируемость.

3. Consumers (Потребители)
Это приложения, которые читают сообщения из Kafka. Например, аналитическая система, которая собирает данные о покупках для анализа.

4. Topics (Топики)
Топик — это как логическая группа сообщений, объединённых по теме. Например, у тебя может быть топик "заказы" для всех покупок в магазине.

5. Partitions (Партиции)
Чтобы ускорить обработку данных, Kafka делит топики на партиции. Каждая партиция может быть размещена на отдельном брокере.

6. Offset (Смещение)
Offset — это уникальный номер сообщения в партиции. Kafka использует его для отслеживания, какое сообщение прочитано, а какое нет.

---

Почему Kafka масштабируема?

Kafka может обрабатывать миллионы сообщений в секунду, потому что:
Топики делятся на партиции. Производители и потребители могут работать параллельно с разными партициями.
Kafka хранит данные на диске в логах (append-only logs), что делает её быстрой и надёжной.
Данные реплицируются между брокерами, чтобы избежать потерь в случае сбоя.

---

Пример работы Kafka

Онлайн-магазин:

1. Когда пользователь оформляет заказ, веб-приложение отправляет событие (например, "пользователь X купил Y") в Kafka.

2. Kafka помещает это сообщение в топик "заказы".

3. Потребители:

Система доставки забирает сообщение и начинает доставку.
Аналитика сохраняет данные для построения отчётов.
Система уведомлений отправляет письмо покупателю.

---

Углубляемся в архитектуру

1. Репликация
Каждая партиция имеет одну "основную" (leader) копию и несколько "реплик" (followers). Это нужно для отказоустойчивости.

Если один брокер выходит из строя, Kafka переключает leader на одну из реплик.


2. Обработка сообщений

At most once: Сообщение доставляется максимум один раз, но может потеряться.

At least once: Сообщение доставляется как минимум один раз (может быть дублирование).

Exactly once: Сообщение доставляется ровно один раз (самый сложный вариант).


3. Хранение данных
Kafka хранит сообщения на диске. Но вместо того, чтобы удалять прочитанные сообщения, Kafka хранит их до заданного времени (например, 7 дней). Это даёт возможность потребителям перечитывать данные.




---

Зачем использовать Kafka?

Kafka идеально подходит для случаев, когда нужно:
Собирать данные в реальном времени. Например, анализ логов или кликов на сайте.
Создать надёжную систему обмена сообщениями между микросервисами.
Обрабатывать огромные объёмы данных. Например, в IoT или крупных аналитических системах.



---

Полезные инструменты Kafka

1. Kafka Connect
Это фреймворк для интеграции Kafka с другими системами (базами данных, очередями и т. д.).

2. Kafka Streams
Это библиотека для обработки данных внутри Kafka. Например, ты можешь посчитать количество заказов в реальном времени.

3. Schema Registry
Используется для управления схемами данных (обычно в формате Avro или JSON), чтобы потребители и производители понимали, как интерпретировать сообщения.


---

Ресурсы для изучения Kafka

1. Официальная документация
2. Учебник от Confluent — Confluent — это компания, поддерживающая Kafka.
3. Книга Kafka: The Definitive Guide — подробный гид от специалистов.
4. Курс на Coursera: Apache Kafka for Developers.
5. Видео-курс на YouTube.

